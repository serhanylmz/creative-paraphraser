{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e306d44-4eeb-433d-b1a2-e1c5c8dae429",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf22d52-4a8c-43b3-8a88-6d833fece31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "from datasets import load_dataset\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee28abcc-4314-4535-9c5e-2d908830a68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter_session\n"
     ]
    }
   ],
   "source": [
    "!tmux display-message -p '#S'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773afbf9-54d1-4e3a-923a-e656504d324a",
   "metadata": {},
   "source": [
    "## Load and Process the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a65a7d-aaf3-4253-a4b9-4bc2afafb160",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569903d-5eca-42e9-b3ae-e8db3fe86adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"quora\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cafbba5-ba1e-4722-8c71-b6798794869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(lambda x: x['is_duplicate'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c10653-6a0d-4ef3-b065-fe12ec8c8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to flatten and prepare the data\n",
    "def prepare_data(examples):\n",
    "    # Create lists to store processed examples\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    \n",
    "    # Process each entry\n",
    "    for question_pair in examples['questions']:\n",
    "        # Assuming each entry in 'questions' has two questions\n",
    "        if len(question_pair['text']) == 2:\n",
    "            input_texts.append(\"paraphrase: \" + question_pair['text'][0])\n",
    "            target_texts.append(question_pair['text'][1])\n",
    "    \n",
    "    # Return a dictionary of processed examples\n",
    "    return {'input_text': input_texts, 'target_text': target_texts}\n",
    "\n",
    "# Apply the function to each entry in the dataset\n",
    "processed_datasets = dataset.map(prepare_data, batched=True, remove_columns=['questions', 'is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03224124-f535-4f63-adc6-32587bcc7862",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d2d69-cd22-4475-9b45-e4493fbceada",
   "metadata": {},
   "source": [
    "#### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b5998fd-eaa1-4c48-9842-28d18b1e741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "def load_and_process_quora():\n",
    "    dataset = load_dataset(\"quora\", trust_remote_code=True)\n",
    "    all_data = []\n",
    "    \n",
    "    for split in dataset.keys():\n",
    "        df = pd.DataFrame(dataset[split])\n",
    "        df = df[df['is_duplicate'] == 1]\n",
    "        \n",
    "        original = []\n",
    "        paraphrased = []\n",
    "        \n",
    "        for row in df['questions']:\n",
    "            if len(row['text']) == 2:\n",
    "                original.append(row['text'][0])\n",
    "                paraphrased.append(row['text'][1])\n",
    "        \n",
    "        all_data.append(pd.DataFrame({'original': original, 'paraphrased': paraphrased}))\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def load_and_process_paws():\n",
    "    dataset = load_dataset(\"paws\", \"labeled_final\")\n",
    "    all_data = []\n",
    "    \n",
    "    for split in dataset.keys():\n",
    "        df = pd.DataFrame(dataset[split])\n",
    "        df = df[df['label'] == 1]\n",
    "        all_data.append(df[['sentence1', 'sentence2']].rename(columns={'sentence1': 'original', 'sentence2': 'paraphrased'}))\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def load_and_process_mrpc():\n",
    "    dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "    all_data = []\n",
    "    \n",
    "    for split in dataset.keys():\n",
    "        df = pd.DataFrame(dataset[split])\n",
    "        df = df[df['label'] == 1]\n",
    "        all_data.append(df[['sentence1', 'sentence2']].rename(columns={'sentence1': 'original', 'sentence2': 'paraphrased'}))\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def load_and_process_paranmt(file_path):\n",
    "    # Read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Process each line\n",
    "    original = []\n",
    "    paraphrased = []\n",
    "    scores = []\n",
    "    \n",
    "    for line in lines:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 3:\n",
    "            orig, para, score = parts\n",
    "            score = float(score)\n",
    "            if (0.76 <= score <= 0.78 and\n",
    "                30 <= len(orig) <= 40 and\n",
    "                30 <= len(para) <= 40 and\n",
    "                not re.search(r'\\d', orig) and\n",
    "                not re.search(r'\\d', para)):\n",
    "                original.append(orig)\n",
    "                paraphrased.append(para)\n",
    "                scores.append(score)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'original': original,\n",
    "        'paraphrased': paraphrased\n",
    "        #'score': scores\n",
    "    })\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "572d1106-591e-456f-b584-6bdf873f65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process each dataset\n",
    "quora_df = load_and_process_quora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad2dc99b-558b-4baa-a354-3f3ff0b71c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>paraphrased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149258</th>\n",
       "      <td>What are some outfit ideas to wear to a frat p...</td>\n",
       "      <td>What are some outfit ideas wear to a frat them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149259</th>\n",
       "      <td>Why is Manaphy childish in Pokémon Ranger and ...</td>\n",
       "      <td>Why is Manaphy annoying in Pokemon ranger and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149260</th>\n",
       "      <td>How does a long distance relationship work?</td>\n",
       "      <td>How are long distance relationships maintained?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149261</th>\n",
       "      <td>What does Jainism say about homosexuality?</td>\n",
       "      <td>What does Jainism say about Gays and Homosexua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149262</th>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 original  \\\n",
       "0       Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "1                          How can I be a good geologist?   \n",
       "2             How do I read and find my YouTube comments?   \n",
       "3                    What can make Physics easy to learn?   \n",
       "4             What was your first sexual experience like?   \n",
       "...                                                   ...   \n",
       "149258  What are some outfit ideas to wear to a frat p...   \n",
       "149259  Why is Manaphy childish in Pokémon Ranger and ...   \n",
       "149260        How does a long distance relationship work?   \n",
       "149261         What does Jainism say about homosexuality?   \n",
       "149262          Do you believe there is life after death?   \n",
       "\n",
       "                                              paraphrased  \n",
       "0       I'm a triple Capricorn (Sun, Moon and ascendan...  \n",
       "1               What should I do to be a great geologist?  \n",
       "2                  How can I see all my Youtube comments?  \n",
       "3                 How can you make physics easy to learn?  \n",
       "4                  What was your first sexual experience?  \n",
       "...                                                   ...  \n",
       "149258  What are some outfit ideas wear to a frat them...  \n",
       "149259  Why is Manaphy annoying in Pokemon ranger and ...  \n",
       "149260    How are long distance relationships maintained?  \n",
       "149261  What does Jainism say about Gays and Homosexua...  \n",
       "149262         Is it true that there is life after death?  \n",
       "\n",
       "[149263 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30df6f09-c6ee-480b-af14-cd4465606d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "paws_df = load_and_process_paws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b2941c6-4bb8-44dc-a59d-a482cb1fa9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>paraphrased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
       "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When comparable rates of flow can be maintaine...</td>\n",
       "      <td>The results are high when comparable flow rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
       "      <td>It is the seat of the district of Zerendi in A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Henry Henry Harman was born on 17 Febr...</td>\n",
       "      <td>William Henry Harman was born in Waynesboro , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>With a discrete amount of probabilities Formul...</td>\n",
       "      <td>Given a discrete set of probabilities formula ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28899</th>\n",
       "      <td>In Advent , the traditional `` Tauberbischofsh...</td>\n",
       "      <td>During Advent , the traditional `` Tauberbisch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28900</th>\n",
       "      <td>In 2002 , the song was released by British pro...</td>\n",
       "      <td>In 2002 , the song was published by the Britis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28901</th>\n",
       "      <td>Tommy Connolly , who plays Rory Jennings , pla...</td>\n",
       "      <td>Tommy Connolly , who plays Rory Jennings , pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28902</th>\n",
       "      <td>Monroe Meadows , in Yosemite valley near Brida...</td>\n",
       "      <td>Monroe Meadows , in Yosemite Valley near Brida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28903</th>\n",
       "      <td>In 2014 the site launched iOS and Android appl...</td>\n",
       "      <td>In 2014 launched the site iOS and Android - ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                original  \\\n",
       "0      The NBA season of 1975 -- 76 was the 30th seas...   \n",
       "1      When comparable rates of flow can be maintaine...   \n",
       "2      It is the seat of Zerendi District in Akmola R...   \n",
       "3      William Henry Henry Harman was born on 17 Febr...   \n",
       "4      With a discrete amount of probabilities Formul...   \n",
       "...                                                  ...   \n",
       "28899  In Advent , the traditional `` Tauberbischofsh...   \n",
       "28900  In 2002 , the song was released by British pro...   \n",
       "28901  Tommy Connolly , who plays Rory Jennings , pla...   \n",
       "28902  Monroe Meadows , in Yosemite valley near Brida...   \n",
       "28903  In 2014 the site launched iOS and Android appl...   \n",
       "\n",
       "                                             paraphrased  \n",
       "0      The 1975 -- 76 season of the National Basketba...  \n",
       "1      The results are high when comparable flow rate...  \n",
       "2      It is the seat of the district of Zerendi in A...  \n",
       "3      William Henry Harman was born in Waynesboro , ...  \n",
       "4      Given a discrete set of probabilities formula ...  \n",
       "...                                                  ...  \n",
       "28899  During Advent , the traditional `` Tauberbisch...  \n",
       "28900  In 2002 , the song was published by the Britis...  \n",
       "28901  Tommy Connolly , who plays Rory Jennings , pla...  \n",
       "28902  Monroe Meadows , in Yosemite Valley near Brida...  \n",
       "28903  In 2014 launched the site iOS and Android - ap...  \n",
       "\n",
       "[28904 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd56bfaa-e3d0-446f-8cc1-5c0115b0f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrpc_df = load_and_process_mrpc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0aa24c0-9dd2-49ee-98ba-b15ded703163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>paraphrased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amrozi accused his brother , whom he called \" ...</td>\n",
       "      <td>Referring to him as only \" the witness \" , Amr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10 , the ship 's owners had published ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The stock rose $ 2.11 , or about 11 percent , ...</td>\n",
       "      <td>PG &amp; E Corp. shares jumped $ 1.63 or 8 percent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Revenue in the first quarter of the year dropp...</td>\n",
       "      <td>With the scandal hanging over Stewart 's compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
       "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>Gehring waived extradition Monday during a hea...</td>\n",
       "      <td>Gehring waived extradition Monday during a hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>\" I am advised that certain allegations of cri...</td>\n",
       "      <td>\" I am advised that certain allegations of cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>The deal , approved by both companies ' board ...</td>\n",
       "      <td>The acquisition has been approved by both comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>Last week the power station ’ s US owners , AE...</td>\n",
       "      <td>The news comes after Drax 's American owner , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
       "      <td>The virus spreads when unsuspecting computer u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               original  \\\n",
       "0     Amrozi accused his brother , whom he called \" ...   \n",
       "1     They had published an advertisement on the Int...   \n",
       "2     The stock rose $ 2.11 , or about 11 percent , ...   \n",
       "3     Revenue in the first quarter of the year dropp...   \n",
       "4     The DVD-CCA then appealed to the state Supreme...   \n",
       "...                                                 ...   \n",
       "3895  Gehring waived extradition Monday during a hea...   \n",
       "3896  \" I am advised that certain allegations of cri...   \n",
       "3897  The deal , approved by both companies ' board ...   \n",
       "3898  Last week the power station ’ s US owners , AE...   \n",
       "3899  Sobig.F spreads when unsuspecting computer use...   \n",
       "\n",
       "                                            paraphrased  \n",
       "0     Referring to him as only \" the witness \" , Amr...  \n",
       "1     On June 10 , the ship 's owners had published ...  \n",
       "2     PG & E Corp. shares jumped $ 1.63 or 8 percent...  \n",
       "3     With the scandal hanging over Stewart 's compa...  \n",
       "4     The DVD CCA appealed that decision to the U.S....  \n",
       "...                                                 ...  \n",
       "3895  Gehring waived extradition Monday during a hea...  \n",
       "3896  \" I am advised that certain allegations of cri...  \n",
       "3897  The acquisition has been approved by both comp...  \n",
       "3898  The news comes after Drax 's American owner , ...  \n",
       "3899  The virus spreads when unsuspecting computer u...  \n",
       "\n",
       "[3900 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrpc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7049671f-708a-4465-ba2a-e959b5c2787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paranmt_df = load_and_process_paranmt('./para-nmt-50m.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ebc924e-2179-4da3-983b-d29937ced781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>paraphrased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She must not have recognized you.</td>\n",
       "      <td>she probably didn't recognize you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just - I was just... tired, you know.</td>\n",
       "      <td>I'm just... I'm really tired, you know?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David, we're not here to drink wine.</td>\n",
       "      <td>David, we're not here for wine, okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Want to join us in the shelter?</td>\n",
       "      <td>would you like to join us in the shed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shit, this one I can't even pronounce.</td>\n",
       "      <td>gosh, I can't even pronounce this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118515</th>\n",
       "      <td>Raylene. Hi. I need to talk to you.</td>\n",
       "      <td>Raylan, I need to talk to you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118516</th>\n",
       "      <td>What happened to the money I gave you?</td>\n",
       "      <td>what happened to the money from me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118517</th>\n",
       "      <td>Sometimes it's like there's two of him.</td>\n",
       "      <td>sometimes it's like being like two.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118518</th>\n",
       "      <td>I tried to remain as numb as possible.</td>\n",
       "      <td>I tried to be as insensitive as I could.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118519</th>\n",
       "      <td>He was your friend - Trevelyan.</td>\n",
       "      <td>was he a friend of yours, Trevelyan?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        original  \\\n",
       "0              She must not have recognized you.   \n",
       "1       It just - I was just... tired, you know.   \n",
       "2           David, we're not here to drink wine.   \n",
       "3                Want to join us in the shelter?   \n",
       "4         Shit, this one I can't even pronounce.   \n",
       "...                                          ...   \n",
       "118515       Raylene. Hi. I need to talk to you.   \n",
       "118516    What happened to the money I gave you?   \n",
       "118517   Sometimes it's like there's two of him.   \n",
       "118518    I tried to remain as numb as possible.   \n",
       "118519           He was your friend - Trevelyan.   \n",
       "\n",
       "                                     paraphrased  \n",
       "0             she probably didn't recognize you.  \n",
       "1        I'm just... I'm really tired, you know?  \n",
       "2          David, we're not here for wine, okay?  \n",
       "3         would you like to join us in the shed?  \n",
       "4             gosh, I can't even pronounce this.  \n",
       "...                                          ...  \n",
       "118515            Raylan, I need to talk to you.  \n",
       "118516       what happened to the money from me?  \n",
       "118517       sometimes it's like being like two.  \n",
       "118518  I tried to be as insensitive as I could.  \n",
       "118519      was he a friend of yours, Trevelyan?  \n",
       "\n",
       "[118520 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paranmt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b244d30c-6546-400f-a654-71d636cebaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "combined_df = pd.concat([quora_df, paws_df, mrpc_df, paranmt_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9437e322-dc1a-440f-9103-41f3d7bd4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "combined_df = combined_df.drop_duplicates(subset=['original', 'paraphrased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f0af880-3365-422c-8e02-fe5382a59e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7783bb66-725d-4f1b-9bb7-b5ac36ba9ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (298102, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combined dataset shape: {combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a378310-44f6-4d40-bf95-8d0398ed2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>paraphrased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I add more details to Quora like this s...</td>\n",
       "      <td>How can I add more details when I am submittin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the disadvantage of option subject ant...</td>\n",
       "      <td>What are disadvantages of anthropology?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clark has some explaining to do.</td>\n",
       "      <td>Clark has something to explain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"You have great skill with your hands\"</td>\n",
       "      <td>\"you're good with your hands.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How could I improve my English pronunciation?</td>\n",
       "      <td>How can I increase my English fluency?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298097</th>\n",
       "      <td>What are some ways people make money without a...</td>\n",
       "      <td>How can I make my money make money?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298098</th>\n",
       "      <td>I will speak with you alone, Kirk.</td>\n",
       "      <td>I'd like to be alone with you, Kirk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298099</th>\n",
       "      <td>Why do I see questions with basic grammatical ...</td>\n",
       "      <td>Why do I always get a notification from Quora ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298100</th>\n",
       "      <td>Who is better Trump or Clinton?</td>\n",
       "      <td>Who is better Donald Trump or Hillary Clinton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298101</th>\n",
       "      <td>What is the best porn movie ever?</td>\n",
       "      <td>What are some of the best porn movies?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 original  \\\n",
       "0       How do I add more details to Quora like this s...   \n",
       "1       What is the disadvantage of option subject ant...   \n",
       "2                        Clark has some explaining to do.   \n",
       "3                  \"You have great skill with your hands\"   \n",
       "4           How could I improve my English pronunciation?   \n",
       "...                                                   ...   \n",
       "298097  What are some ways people make money without a...   \n",
       "298098                 I will speak with you alone, Kirk.   \n",
       "298099  Why do I see questions with basic grammatical ...   \n",
       "298100                    Who is better Trump or Clinton?   \n",
       "298101                  What is the best porn movie ever?   \n",
       "\n",
       "                                              paraphrased  \n",
       "0       How can I add more details when I am submittin...  \n",
       "1                 What are disadvantages of anthropology?  \n",
       "2                         Clark has something to explain.  \n",
       "3                          \"you're good with your hands.\"  \n",
       "4                  How can I increase my English fluency?  \n",
       "...                                                   ...  \n",
       "298097                How can I make my money make money?  \n",
       "298098               I'd like to be alone with you, Kirk.  \n",
       "298099  Why do I always get a notification from Quora ...  \n",
       "298100  Who is better Donald Trump or Hillary Clinton ...  \n",
       "298101             What are some of the best porn movies?  \n",
       "\n",
       "[298102 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "815fba09-fac2-4da1-a7fa-dfb0fd81ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined dataset\n",
    "combined_df.to_csv('combined_paraphrase_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5a86e10-08ee-4f1f-9c3f-2c1a77354125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79b87d4b-4060-4297-818e-fcec1cd31d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (283196, 2)\n",
      "Test set shape: (14906, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd543640-4e0c-4af5-909f-99c65e56df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train and test sets\n",
    "train_df.to_csv('paraphrase_train.csv', index=False)\n",
    "test_df.to_csv('paraphrase_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f09ae-60d6-424f-9df3-9c2ad7eb317f",
   "metadata": {},
   "source": [
    "# Newest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae80445-fd94-4ca8-aa13-29963d9cffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Custom dataset class\n",
    "class ParaphraseDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        input_text = f\"paraphrase: {row['original']}\"\n",
    "        target_text = row['paraphrased']\n",
    "\n",
    "        input_encoding = self.tokenizer(input_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        target_encoding = self.tokenizer(target_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        labels = target_encoding.input_ids\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.flatten(),\n",
    "            'attention_mask': input_encoding.attention_mask.flatten(),\n",
    "            'labels': labels.flatten()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824d05c-865d-48f9-b9d7-59c21ace7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-large').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24b513-0d2b-4ee3-a262-13e70c17b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('combined_paraphrase_dataset.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = ParaphraseDataset(train_df, tokenizer)\n",
    "val_dataset = ParaphraseDataset(val_df, tokenizer)\n",
    "\n",
    "batch_size = 16  # Increased batch size\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c127ff-0e87-4239-b3f4-bb94070097de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=\"t5-paraphrase\", name=\"training-run-2\")\n",
    "\n",
    "# Log model architecture\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40484b4d-8c23-4d7e-acc1-3f18ca231442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # Reduced learning rate\n",
    "num_epochs = 5  # Increased number of epochs\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "num_warmup_steps = int(0.1 * num_training_steps)  # 10% of total steps for warmup\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",  # Changed to cosine schedule with warmup\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Log hyperparameters\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"model_name\": \"t5-large\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"cosine with warmup\",\n",
    "    \"warmup_steps\": num_warmup_steps,\n",
    "    \"train_size\": len(train_df),\n",
    "    \"val_size\": len(val_df)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0273b-9108-49f9-8de1-540756e9ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)  # Added gradient clipping\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # Log training metrics\n",
    "        wandb.log({\n",
    "            \"train_loss\": loss.item(),\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"epoch\": epoch,\n",
    "            \"step\": epoch * len(train_dataloader) + step\n",
    "        })\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    # Log validation metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": val_loss\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fac150-75d7-49fe-b32d-4d9b77f0c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./t5_paraphrase_model_improved\")\n",
    "tokenizer.save_pretrained(\"./t5_paraphrase_model_improved\")\n",
    "\n",
    "print(\"Training completed and model saved!\")\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c71475-e900-4470-a223-155d8334e18e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# New Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5ec82f9-6aa6-4abb-8b8d-7cf32b7bef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Custom dataset class\n",
    "class ParaphraseDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        input_text = f\"paraphrase: {row['original']}\"\n",
    "        target_text = row['paraphrased']\n",
    "\n",
    "        input_encoding = self.tokenizer(input_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        target_encoding = self.tokenizer(target_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        labels = target_encoding.input_ids\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encoding.input_ids.flatten(),\n",
    "            'attention_mask': input_encoding.attention_mask.flatten(),\n",
    "            'labels': labels.flatten()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3065cc1-6e2f-42d1-8365-15ea91e7e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('combined_paraphrase_dataset.csv')\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba414960-2ea5-4775-9603-5739b395bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-large').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9081933c-4413-44e6-a445-382a36aa53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = ParaphraseDataset(train_df, tokenizer)\n",
    "val_dataset = ParaphraseDataset(val_df, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d30aa382-d92c-4778-ad7a-495349b4fd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msrhnylmz14\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cta/users/serhan.yilmaz/llama3-phi3/QuestionGeneration/T5-paraphraser/creative-paraphraser/wandb/run-20240703_162818-i1fv2gna</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/srhnylmz14/t5-paraphrase/runs/i1fv2gna' target=\"_blank\">training-run-1</a></strong> to <a href='https://wandb.ai/srhnylmz14/t5-paraphrase' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/srhnylmz14/t5-paraphrase' target=\"_blank\">https://wandb.ai/srhnylmz14/t5-paraphrase</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/srhnylmz14/t5-paraphrase/runs/i1fv2gna' target=\"_blank\">https://wandb.ai/srhnylmz14/t5-paraphrase/runs/i1fv2gna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/srhnylmz14/t5-paraphrase/runs/i1fv2gna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2ad497dec220>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=\"t5-paraphrase\", name=\"training-run-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a59b53cb-2e09-4102-b733-ed7977da98ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log model architecture\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04092b04-931d-40f7-9748-f81965f0bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Log hyperparameters\n",
    "wandb.config.update({\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"batch_size\": 8,\n",
    "    \"model_name\": \"t5-large\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"scheduler\": \"linear\",\n",
    "    \"train_size\": len(train_df),\n",
    "    \"val_size\": len(val_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3aa3548-a19a-4382-a974-9ed5361072ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0594abb9cb4aa38ad46a7aa4160e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100611 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      8\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     11\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1770\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# Rescale output before projecting on vocab\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m sequence_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m-> 1770\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1772\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # Log training metrics\n",
    "        wandb.log({\n",
    "            \"train_loss\": loss.item(),\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "            \"epoch\": epoch,\n",
    "            \"step\": epoch * len(train_dataloader) + step\n",
    "        })\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            val_loss += outputs.loss.item()\n",
    "    val_loss /= len(val_dataloader)\n",
    "\n",
    "    # Log validation metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": val_loss\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12424767-3ad7-4357-9b93-b5a9d58d6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./t5_paraphrase_model\")\n",
    "tokenizer.save_pretrained(\"./t5_paraphrase_model\")\n",
    "\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6be3f1-8424-4765-a536-f01bb7b0095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b96dda-1c68-4453-b629-a5f4bc4c3c3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Old Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2e543a-d430-4f62-932e-44b70f7ca2c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6f3a23-bfb5-4707-ac41-6f3042dbd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
    "\n",
    "# Define the function to tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['target_text'], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac649957-b464-4d58-a5d1-aa7d18af7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenization to all sets in the dataset\n",
    "tokenized_datasets = processed_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf68a34-964e-4043-a56b-5c710304f904",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prepare the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e770cf4-bd7f-495e-8cfc-119bd3913580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a helper function to create the DataLoader\n",
    "def create_dataloader(tokenized_data, batch_size=8):\n",
    "    # Convert list of dictionaries into a format DataLoader can handle\n",
    "    dataset = tokenized_data.remove_columns(['input_text', 'target_text'])  # Remove text columns not needed for training\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    \n",
    "    # Create the DataLoader\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create DataLoaders for training (and optionally validation)\n",
    "train_dataloader = create_dataloader(tokenized_datasets['train'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50581e43-0d67-4fcc-a2bd-61d723a5f6de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Model / Set Up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087843a3-8b51-495b-b2be-a224919d7461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cta/users/serhan.yilmaz/.local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-large').cuda()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 3\n",
    "\n",
    "# Set up the learning rate scheduler\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65def88-ab35-4eee-ac4e-4164c90edb4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352cc47-48ad-431f-b48b-349badd384cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be39fbdaf2fc424598653c501df1924f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b583f-4bd7-40b5-86ff-ebb8e415d487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ee9853-a66f-493c-8cbc-c8ecf3c8fb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./t5_paraphrase_model/tokenizer_config.json',\n",
       " './t5_paraphrase_model/special_tokens_map.json',\n",
       " './t5_paraphrase_model/spiece.model',\n",
       " './t5_paraphrase_model/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./t5_paraphrase_model\")\n",
    "tokenizer.save_pretrained(\"./t5_paraphrase_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7611da9-210d-4a16-9229-296e4e2a57da",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3db36c-7e9a-4342-b607-4ccc21a249c9",
   "metadata": {},
   "source": [
    "## Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc07d08-9ee5-4647-9871-02bdf46dbf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_path = \"./t5_paraphrase_model\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).cuda()\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd4a68-8e11-4432-a68b-a3513846921a",
   "metadata": {},
   "source": [
    "## Function to Generate Paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19974c7f-2164-4273-87c8-4a9483916be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paraphrases(input_text, num_returns=3):\n",
    "    # Encode the input text\n",
    "    input_ids = tokenizer.encode(\"paraphrase: \" + input_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate paraphrases\n",
    "    paraphrases = model.generate(\n",
    "        input_ids,\n",
    "        max_length=50,\n",
    "        num_beams=num_returns,\n",
    "        num_return_sequences=num_returns,\n",
    "        no_repeat_ngram_size=1,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode and print each paraphrase\n",
    "    return [tokenizer.decode(paraphrase, skip_special_tokens=True) for paraphrase in paraphrases]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e134680-4a70-4bf4-8f40-aacfefbfaa63",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67b44182-948d-4c2a-a235-3a3e7c4ba4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrase 1: What is the best way to learn artificial intelligence?\n",
      "Paraphrase 2: How do I learn artificial intelligence?\n",
      "Paraphrase 3: What is the best way to learn Artificial Intelligence?\n",
      "Paraphrase 4: What are the best ways to learn artificial intelligence?\n",
      "Paraphrase 5: How can I learn artificial intelligence?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sentence = \"What is the best way to learn artificial intelligence?\"\n",
    "paraphrase_outputs = generate_paraphrases(input_sentence, num_returns=5)\n",
    "for i, paraphrase in enumerate(paraphrase_outputs, 1):\n",
    "    print(f\"Paraphrase {i}: {paraphrase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d596062-c2fc-4265-ace3-12bb6d202ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrase 1: What occupation did Albert Einstein have?\n",
      "Paraphrase 2: What was Albert Einstein's occupation?\n",
      "Paraphrase 3: What occupation did Albert Einstein hold?\n",
      "Paraphrase 4: What occupations did Albert Einstein have?\n",
      "Paraphrase 5: What job did Albert Einstein have?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sentence = \"What occupation did Albert Einstein have?\"\n",
    "paraphrase_outputs = generate_paraphrases(input_sentence, num_returns=5)\n",
    "for i, paraphrase in enumerate(paraphrase_outputs, 1):\n",
    "    print(f\"Paraphrase {i}: {paraphrase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cf7c724d-64d9-4a6b-b16d-bed77851e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrase 1: What nationality did the physicist Albert Einstein have?\n",
      "Paraphrase 2: What nationality did physicist Albert Einstein have?\n",
      "Paraphrase 3: What nationality did Albert Einstein have?\n",
      "Paraphrase 4: What nationality did physicist Albert Einstein belong to?\n",
      "Paraphrase 5: What nationality did physicist Albert Einstein come from?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sentence = \"What nationality did the physicist Albert Einstein have?\"\n",
    "paraphrase_outputs = generate_paraphrases(input_sentence, num_returns=5)\n",
    "for i, paraphrase in enumerate(paraphrase_outputs, 1):\n",
    "    print(f\"Paraphrase {i}: {paraphrase}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96282d13-2b9b-4930-b4b3-dbb72b30d793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrase 1: The restaurant is a cut-off space on one side of the stairs, with fake brick columns and faux wood floors dominating an air foetid despondency\n",
      "Paraphrase 2: The restaurant is a cut-off space on one side of the stairs, with fake brick columns and faux wood floors dominating an air foetid despair.\n",
      "Paraphrase 3: The restaurant is a cut-off space on one side of the stairs, with fake brick columns and faux wood floors dominating an air foetid despairance.\n",
      "Paraphrase 4: The restaurant is a cut-off space on one side of the stairs, with fake brick columns and faux wood floors dominating.\n",
      "Paraphrase 5: The restaurant is a cut-off space on one side of the stairs, with fake brick columns and faux wood floors.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_sentence = \"The restaurant is a carved-off space up a couple of stairs to one side, dominated by faux bare-brick columns, faux-wood floors and an air of foetid despondency\"\n",
    "paraphrase_outputs = generate_paraphrases(input_sentence, num_returns=5)\n",
    "for i, paraphrase in enumerate(paraphrase_outputs, 1):\n",
    "    print(f\"Paraphrase {i}: {paraphrase}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
